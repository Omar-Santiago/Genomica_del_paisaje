########### pauqetes ###########
#remove.packages("promises")
#install.packages("promises")
#install.packages("devtools")
library(usethis)
library(devtools)
#devtools::install_github("DevonDeRaad/SNPfiltR")
#devtools::install_github(repo="knausb/vcfR")
#install_github("jdstorey/qvalue")
library("qvalue")
#devtools::install_github("whitlock/OutFLANK")
#library(OutFLANK)
library(SNPfiltR)
library(vcfR)
library(adegenet)
#devtools::install_github("TheWangLab/algatr")
library(algatr)
#nstall.packages("factoextra")
#library(ggplot2)
#library(factoextra)
#devtools::install_github("spflanagan/fsthet_analysis/fsthet")
library(fsthet)
#install.packages("here")
#library(here)
#install_github("zhengxwen/SNPRelate")
#install_github("zhengxwen/SeqArray")
#library(gdsfmt)
#library(SNPRelate)
#library(SeqArray)
#install.packages("dartR", dependencies = T)
library(dartR)
#devtools::install_github("thierrygosselin/radiator")
#library(radiator)

################ paso inicial ##################
# primero debemos tener nuestros datos feneticos, los cuales estan en la carpeta salida_cluster,
# es necesario separar los datos del bosque y de las camaras asi que use el la siguiente linea 
# en la terminal: 
#  vcftools --vcf populations.snps.vcf --keep muestras_bosque.txt --recode --recode-INFO-all --out PNDL 

setwd("F:/pasos_en_R/filtros_post_ensamble/")

rm(list = ls())

vcfR_0 <- read.vcfR("PNDL.recode.vcf")
vcfR_0


# este paso genera graficas con los datos no filtrados
# la linea roja significa la media de ...
hard_filter(vcfR=vcfR_0)

# ahora eliminamos los loci con una profundidad menor a 10 y una calida menor a 35
vcfR_1<-hard_filter(vcfR=vcfR_0, depth = 10)
vcfR_1
#hard_filter(vcfR=vcfR)

# ahora aplicamos un filtro del balance de alelos
vcfR_2<-filter_allele_balance(vcfR_1)
vcfR_2

# hacemos una exploracion de la profundidad maxima, es necesario elimanar estos SNPs porque pueden ser paralogos 
max_depth(vcfR_2)
vcfR_3<-max_depth(vcfR_2, maxdepth = 100)
vcfR_3

# ahora vemos el missing data de los idividuos
popmap <- read.csv("popmap_omar.csv", header = T)
missing_by_sample(vcfR=vcfR_3, popmap = popmap)
# eliminamos individuos con missing data mayor al 80%
vcfR_4<-missing_by_sample(vcfR=vcfR_3, cutoff = .9)

#subset popmap to only include retained individuals
popmap<-popmap[popmap$id %in% colnames(vcfR_4@gt),]
vcfR_4

#remove invariant sites generated by dropping individuals
vcfR_5<-min_mac(vcfR_4, min.mac = 2)
vcfR_5

# antes de aplicar el filtro de missing data en los loci haces un diagnostico con diferentes 
# umbrales para permitir missing data. Al parecer mientras mas alto es el umbral mas es la separacion
# entre los individuos, asi que nos quedaremos con el umbral de 0.09
miss<-assess_missing_data_pca(vcfR=vcfR_5, popmap = popmap, thresholds = c(.5,.6,.7,.8), clustering = FALSE)
vcfR_miss0.7<-missing_by_snp(vcfR_5, cutoff = .75)


# ahora vamos a hacer un diagnostico con diferentes valores de mac
#vcfR_miss0.7 <- min_mac(vcfR_miss0.7, min.mac = 1)
#vcfR_miss0.85 <- min_mac(vcfR_miss0.85, min.mac = 1)
#miss<-assess_missing_data_tsne(vcfR_miss0.7, popmap, clustering = FALSE)
#miss<-assess_missing_data_tsne(vcfR_miss0.85, popmap, clustering = FALSE)

# finalmente eliminamos SNPs ligados en ventanas de 100pb, abies tiene una recombinacion 
# de 1000pb?
# ld_prune es un filtro muy muy fuerte, asi que usare distance_thin
vcfR_miss0.7

pre_vcf <- distance_thin(vcfR_miss0.7, min.distance = 100)
pre_vcf
vcfR::write.vcf(pre_vcf, "pre_vcf.vcf.gz")
vcfR::write.vcf(pre_vcf, "pre_vcf.vcf")


################### eliminar sesgo placa ###################
# nosotros tenemos un sesgo dado por las placas, asi que antes de aplicar mas filtros es necesario
# eliminar los SNPs que nos generen el efecto de las placas (OÂ´Leary at al., 2018)
# primero debemos crear un popmap donde el numero de la placa sea la "poblacion" para despues realizar un test de outlayers,
# una vez identificados los snps atipicos estos se eliminaran   

vcfR_p <- read.vcfR("pre_vcf.vcf.gz")

# asiganamos los individuos a las placas
pop_placa <- read.csv("popmap_placa.csv", header = T)
popmap <- read.csv("popmap_omar.csv", header = T)
popmap<-popmap[popmap$id %in% colnames(vcfR_p@gt),]
ind_placas <- pop_placa[pop_placa$id %in% popmap$id, ]
ind_placas

# convetimosa objeto genlight
placa_genl <- vcfR2genlight(vcfR_p)
placa_genl
# asignamos las poblaciones artificiales
pop(placa_genl) <- ind_placas$placa

# Realizamos un DAPC para ver el efecto de la placa 
pramx<-xvalDapc(tab(placa_genl,NA.method="mean"), pop(placa_genl))
colores <- c("#abd9e9","#313695","#ffd700","#9e0852")
plotdapc <- scatter(pramx$DAPC, mstree = T, clabel = T, lwd = 2, grid=T, cex=3,
                    col = colores, cleg = 0.80, posi.da = "bottomleft" )

# creamos una matriz con formato similar a genepop
geno <- extract.gt(vcfR_p) # Character matrix containing the genotypes
geno <- t(geno)
G <- matrix(geno, nrow = nrow(geno), ncol = ncol(geno))

G[geno %in% c("0/0", "0|0", NA)] <- "0101"
G[geno  %in% c("0/1", "0|1")] <- "0102"
G[geno  %in% c("1/0", "1|0")] <- "0201"
G[geno %in% c("1/1", "1|1")] <- "0202"

colnames(G) <- vcfR_p@fix[,3]
pop.info <- ind_placas$placa
ind.names <- ind_placas$id
G <- cbind(pop.info, ind.names, G)

# calculamos los Fst y Ht para los loci (Flanagan & Jones, (2017)
fsts<-calc.actual.fst(G,"fst")
head(fsts)

par(mar=c(4,4,1,1))
plot(fsts$Ht, fsts$Fst,xlab="Ht",ylab="Fst",pch=19)

# estimamos los outlayers y los guardamos para eliminarlos 
quant.out<-fst.boot(G, bootstrap = FALSE)
outliers<-find.outliers(fsts,boot.out=quant.out)
snps_eliminar <- as.vector(outliers$Locus)
write.csv(snps_eliminar, "outliers_efecto_placa.csv")
head(outliers)
out.dat<-fsthet(G)
head(out.dat)

# creamos un genlight y eliminamos los SNPs con fst altos que causan 
# el efecto placa. Es necesario instalar dart
gen_eliminar <- gl.read.vcf("pre_vcf.vcf.gz")
gen_eliminar
list_eliminar <- read.table("outliers_efecto_placa.txt")
list_eliminar$V1

# eliminar loci de un genlight
gen_limpio <- gl.drop.loc(gen_eliminar, loc.list = list_eliminar$V1, 
            verbose = 3)

# guardamos en formato vcf y genpop(para usar con el paquete LEA)
gl2geno(gen_limpio, outfile = "snps_geno", outpath = ".", verbose = 3)


# realizamos dapc
# asignamos las poblaciones artificiales
pop(gen_limpio) <- ind_placas$placa

# Realizamos un DAPC para ver el efecto de la placa 
pra_limpio<-xvalDapc(tab(gen_limpio,NA.method="mean"), pop(gen_limpio))
colores <- c("#abd9e9","#313695","#ffd700","#9e0852")
plotdapc <- scatter(pra_limpio$DAPC, mstree = T, clabel = T, lwd = 2, grid=T, cex=3,
                    col = colores, cleg = 0.80, posi.da = "bottomleft" )

############################ crar un vcf ################
# debido a que en R es dificil gardar un vcf voy a crar una lista de los
# SNPs que se han eliminado hasta el momento 

# la lista de outlaiers de las placas ya esta, solo falta aislar 
# los loci que no estan en gen_limpio pero si estan en pre_vcf, estos 
# aislados son los que se eliminaran del archivo PNDL.recode.vcf

# creamos listas con los ID de los loci
all_loci <- as.data.frame(vcfR_0@fix)
loc.names <- gen_limpio@loc.names
lista_reducida <- as.data.frame(loc.names)

# aislamos y guardamos los loci que no estan en el archivo de gen_limpio 
# (el cual ya tiene eliminado outlaier de efecto placa y filtros previos)
lista_eliminar<-all_loci[!all_loci$ID %in% lista_reducida$loc.names,]
write.csv(lista_eliminar$ID, "todos_loci_eliminados.csv")

# este paso elimina los loci de una lista
# vcftools --vcf bosque_limpios.recode.vcf --exclude todos_loci_eliminados.txt --recode --recode-INFO-all --out snps_limpios

# este paso elimina el individuo PP2_NNAP1
#vcftools --vcf snps_limpios.recode.vcf --remove-indv PP2_NNAP1 --recode --recode-INFO-all --out bosque_limpios

########################## filtros con SNPfiltR ######################

vcfR <- read.vcfR("snps_limpios.recode.vcf")
vcfR

# este paso genera graficas con los datos no filtrados
# la linea roja significa la media de ...
hard_filter(vcfR=vcfR)

# ahora eliminamos los loci con una profundidad menor a 10 y una calida menor a 35
vcfR<-hard_filter(vcfR=vcfR, depth = 10)
vcfR
#hard_filter(vcfR=vcfR)

# ahora aplicamos un filtro del balance de alelos
vcfR<-filter_allele_balance(vcfR)
vcfR

# hacemos una exploracion de la profundidad maxima, es necesario elimanar estos SNPs porque pueden ser paralogos 
#max_depth(vcfR)
vcfR<-max_depth(vcfR, maxdepth = 100)
vcfR

# ahora vemos el missing data de los idividuos
popmap <- read.csv("popmap_omar.csv", header = T)
missing_by_sample(vcfR=vcfR, popmap = popmap)
# eliminamos individuos con missing data mayor al 80%
vcfR<-missing_by_sample(vcfR=vcfR, cutoff = .9)

#subset popmap to only include retained individuals
popmap<-popmap[popmap$id %in% colnames(vcfR@gt),]

#remove invariant sites generated by dropping individuals
vcfR<-min_mac(vcfR, min.mac = 2)
vcfR

# antes de aplicar el filtro de missing data en los loci haces un diagnostico con diferentes 
# umbrales para permitir missing data. Al parecer mientras mas alto es el umbral mas es la separacion
# entre los individuos, asi que nos quedaremos con el umbral de 0.09
miss<-assess_missing_data_pca(vcfR=vcfR, popmap = popmap, thresholds = c(.5,.6,.7,.8), clustering = FALSE)
vcfR_miss0.7<-missing_by_snp(vcfR, cutoff = .7)


# ahora vamos a hacer un diagnostico con diferentes valores de mac
#vcfR_miss0.7 <- min_mac(vcfR_miss0.7, min.mac = 1)
#vcfR_miss0.85 <- min_mac(vcfR_miss0.85, min.mac = 1)
#miss<-assess_missing_data_tsne(vcfR_miss0.7, popmap, clustering = FALSE)
#miss<-assess_missing_data_tsne(vcfR_miss0.85, popmap, clustering = FALSE)

# finalmente eliminamos SNPs ligados en ventanas de 100pb, abies tiene una recombinacion 
# de 1000pb?
# ld_prune es un filtro muy muy fuerte, asi que usare distance_thin
vcfR_miss0.7

pre_vcf <- distance_thin(vcfR_miss0.7, min.distance = 100)
pre_vcf
vcfR::write.vcf(pre_vcf, "pre_vcf.vcf.gz")



# opcion extra 
# ld_prune es un filtro muy muy fuerte
