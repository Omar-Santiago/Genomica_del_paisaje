# 
#Este es un script implementado y basandose en la metodologia de Algatr, la cual es una papeline enfocada en analisis de genomica del paisaje a nivel individuo 
#
# Chambers, E.A., Bishop, A.P., & Wang, I.J. (2023). Individual-based landscape genomics for conservation: An analysis pipeline.
# Molecular Ecology Resources.https://doi.org/10.1111/1755-0998.13884.
#
#primero instalaremos y algatr
#devtools::install_github("TheWangLab/algatr")
library(algatr)
# Instalaremos los paquetes asociados a algatr
#alazygatr_packages()
#data_processing_packages()
#install.packages("vcfr")
library(vcfR)
library(purrr)
library(dplyr)
library(ggplot2)
library(here)
library(sp)
library(raster)
library(adegenet)


#escogemos nuestro directorio de trabajo
setwd("~/Documents/IND_PNDL/estructura")

#                                #
#   Preparacion de los datos     #
#                                #


# Para algunos analisis eliminar cualquier sitio vinculado de nuestros datos evita sesgos en los resultados, por ejemplo, la estimacion de la estructura genetica 
# o analisis de asociacion GxE se pueden ver sobreinflados por alelos en desequilibrio de ligamiento.
# ahora realizaremos una poda de desequilibrio de ligamiento, para ello usaremos: ld_prune()
# La función funciona eliminando primero cualquier variante que ocurra por debajo de una frecuencia de alelo menor determinada y 
# luego podando cualquier variante que tenga una correlación determinada utilizando un enfoque de ventana deslizante.
vcf_ldpruned <- ld_prune(vcf = "~/Documents/IND_PNDL/estructura/SNP.filtrado.HWE.recode.vcf", out_name = "filtrados9", 
                         out_format = "vcf", ld.threshold = 0.9, slide.max.n = 100, maf = 0.5)

ind_PNDL <- read.vcfR("~/Documents/IND_PNDL/GxE/filtrados9_LDpruned/filtrados9_LDpruned_r0.9_n100.vcf")
ind_genlite <- vcfR2genlight(ind_PNDL)
#tranasformamos a un objeto genligth para despues transformar nuestro vcf a una matriz de "dosificacion". 
# Las matrices de "dosificacion" contienen en las filas los individuos y en las columnas los sitios  
dosage <- vcf_to_dosage(ind_PNDL)
dosage[1:5, 1:8]
# la matriz nos muestra que existen multiples NA, esto representa un problema para los metodos de asociacion por lo que tenemos que imputar los datos,
# para ello existen dos metodos, una basado sin informacion previa y otro que utiliza la estructura genetica poblacional (str_impute()), 
# para usos practicos utilizaremos el metodo que no necsita informacion previa 
simple_dos <- simple_impute(dosage)
simple_dos[1:5, 1:8] # Ahora simple_dos lo usaremos para los analisis de estructura y hacer una imputacion con str_impute()


# Ahora vcf_ldpruned lo usaremos para los analisis de estructura y hacer una imputacion con str_impute()




#                                          #
#    Calculo de las distancias geneticas   #
#                  PCA                     #
#                                          #
#                                          #

#install.packages("ecodist")
library(ecodist)
library(ade4)
library(adegenet)
library(algatr)
library(permute)
library(lattice)
library(vegan)
library(algatr)
library(cowplot)

# Debido a que muchos analisis de genomica del paisaje necesitan una matriz de distancias geneticas por pares vamos a calcular una.
# los metodos que algatr puede calcular son:
# Euclidean distance
# Bray-Curtis distance
# Proportion of shared alleles 
# PC-based distance 
# Processing distances generated using Plink 

# los metodos Euclidean, Bray-Curtis y PC no aceptan datos faltantes, por lo que necestamos el arhivo simple_dos
# Shirk et al., 2017 ( https://doi.org/10.1111/1755-0998.12684 ) evaluar diferentes medidad de dstancia genetica a nivel individual y encuentra que en cuando 
# las muestras son pocas y existe una ligera estructura genetica los metodos que usan PC son los mejores
pc_dists <- gen_dist(ind_PNDL, dist_type = "pc", npc_selection = "auto", criticalpoint = 2.4224) # 2.4224 es igual a significancia de 0.005

gen_dist_hm(pc_dists)

# el comando anterior es elq ue viene en Algatr, pero para asegurarnos vamos hacerlo como lo hace Shirk et al 
# (2010; https://doi-org.pbidi.unam.mx:2443/10.1111/j.1365-294X.2010.04745.x)

simple_dos[1:5, 1:8] # nuestra matris G con n x m, donde n son los individuos en filas y m los alelos en columnas
data <- simple_dos
# Realizar el PCA, prcomp es del paquete stats
pca_result <- prcomp(data)
#hacemos un grafico de barras de los componentes princilaesles para escogerlos como estructura neutra en los anaisis de GxE
screeplot(pca_result, npc = 16)
################ esta parte es relevante porque vamos a seleccionar la estructura gentica para nuestro RDA
PCs <- scores(pca_result, choices=c(1:4), display="sites", scaling=0)
Struct_ind <- data.frame(PCs) # ahora este archivo esta listo para usarse en el script GxE_RDA.R y controlar la estructura genetica
write.csv(Struct_ind, "Structura4PCAs.csv")

# para hacer un grafico de nuestro resultados del PCA primero vamos a crear un vector que nos permita adicionar mas informacion de nuestros individuos, 
# en este caso la condicion de sintamaticos y asintomaticos por el ozono 
# para ello primero debo saber cual es el order de mis individios que utilice en el analsis: 
data[1:64,1:1]
# cargamos los metadatos para hacer graficos 
salud <- read.csv("~/Documents/IND_PNDL/metadatos/meta_largos.csv")
group <- as.vector(salud$tree_health_simplified)
# Verificar el vector de grupos
print(group)
#intalamos ggplot
#if (!requireNamespace("ggplot2", quietly = TRUE)) {  install.packages("ggplot2")}
library(ggplot2)
# Extraer las puntuaciones de los tres primeros componentes principales
scores <- pca_result$x[, 1:3]
# Crear un data frame para ggplot2
pca_data <- data.frame(Score1 = scores[,1], Score2 = scores[,2], Score3 = scores[,3], Group = group)
# Gráfico de PCA con ggplot2, coloreando por grupo
ggplot(pca_data, aes(x = Score1, y = Score2, color = Group)) +
  geom_point(alpha = 0.8, size = 3) +
  labs(x = "Primer Componente Principal", y = "Segundo Componente Principal", title = "PCA - Primer vs Segundo Componente") +
  theme_minimal()
# Repetir para las otras combinaciones de componentes
ggplot(pca_data, aes(x = Score1, y = Score3, color = Group)) +
  geom_point(alpha = 0.8, size = 3) +
  labs(x = "Primer Componente Principal", y = "Tercer Componente Principal", title = "PCA - Primer vs Tercer Componente") +
  theme_minimal()

ggplot(pca_data, aes(x = Score2, y = Score3, color = Group)) +
  geom_point(alpha = 0.8, size = 3) +
  labs(x = "Segundo Componente Principal", y = "Tercer Componente Principal", title = "PCA - Segundo vs Tercer Componente") +
  theme_minimal()


# notas: 
# PCA assumes continuous, normally distributed data (Dytham, 2011) <- en  https://doi.org/10.1111/1755-0998.13831



#                             #
#                             #
#           sNMF              #
#                             #
#                             #

library(LEA)

#dir.create("LEA_analyses")
setwd("/home/omar/Documents/IND_PNDL/estructura/sNMF")

# con PGDSpider convertimos el archivo vcf filtrado en ped 
ind_fil_snmf <- ped2geno("/home/omar/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.ped")

# evaluate population genetic structure
# snmf() es una funcion que estima coeficientes individuales de admixture a partir de una matriz genotipica
# estima minimos cuadrados de las proporciones ancestrales y las frecuencias alelicas ancestrales
snmf_estructura = snmf("/home/omar/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.geno", 
                 iterations=100, K=1:10, rep=30, 
                 entropy=T, CPU=4, ploidy=2, 
                 project="new") # call new data

plot(snmf_estructura,lwd=8,col="#9215D0",pch=1, cex=2)

# cargamos el "snmfproject" generado.
snmf_ind_estructura = load.snmfProject("/home/omar/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.snmfProject")

#  ahora realizaremo un grafico de barras que se genera con los valores de una matriz-q, esta matriz se llama de forma indirecta
best=which.min(cross.entropy(snmf_ind_estructura, K=1))

my.colors <- c("tomato", "lightblue",
               "olivedrab", "gold")
barchart(snmf_ind_estructura, K = 1, run = best,
         border = NA, space = 0,
         col = my.colors,
         xlab = "Individuos",
         ylab = "Proporciones ancestrales",
         main = "Ancestria") -> bp
axis(1, at = 1:length(bp$order),
     labels = bp$order, las=1,
     cex.axis = .4)

# ahora que estimamos la estructura neutra vamos a imputar el LFMM para despues hacer un pca
ind_pca <- ped2lfmm("/home/omar/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.ped")
impute(
#"/home/omar/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.lfmm"
snmf_estructura, "/home/omar/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.lfmm",  method = 'mode', K = 1, run = best)

# ahora corremos un pca, para ello nuestro ped lo transformamos a 
pc <- pca("/home/omar/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.lfmm_imputed.lfmm")

project = load.pcaProject("/home/omar/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.lfmm_imputed.pcaProject") 

# con esto estimaremos la estructura gentica neutra 
estructura <- read.table("/home/omar/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.pca/snmf_estructura_filtrados.projections")
estructura2 <- read.table("/home/omar/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.pca/snmf_estructura_filtrados.eigenvectors")


estructura <- read.table("~/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.lfmm_imputed.pca/snmf_estructura_filtrados.lfmm_imputed.projections")
estructura1 <- estructura[1:4]
write.csv(estructura1, "Structura4PCAs.csv")

estruc_eigen <- read.table("~/Documents/IND_PNDL/estructura/sNMF/snmf_estructura_filtrados.lfmm_imputed.pca/snmf_estructura_filtrados.lfmm_imputed.eigenvectors")
estruc_eigen1 <- estruc_eigen[1:4]
write.csv(estruc_eigen1, "Structura4eigenvalues.csv")


#


#                                         #
#     Analisis de estructura genetica     #     
#               TESS                      #
#                                         #


# vamos usar TESS, asiq ue hay que ver: 
# TESS3: fast inference of spatial population structure and genome scans for selection.

library(algatr)
library(here)
library(wingen)
library(tess3r)
library(ggplot2)
library(terra)
library(raster)
library(fields)
library(rworldmap)
library(automap)
library(cowplot)
#para hacer graficos desde TESS
source("http://membres-timc.imag.fr/Olivier.Francois/Conversion.R")
library(RColorBrewer)
source("http://membres-timc.imag.fr/Olivier.Francois/POPSutilities.R")

# necesitamos una matris dosificada, asi que necesitamos el archivo simple_dos
simple_dos[1:65, 1:2]
# tambien vamos a necesitar los datos de las coordfenadas de los individuos 
coord <- read.csv("~/Documents/IND_PNDL/metadatos/coord.csv", row.names = 1)
coord <- coord[-c(3)]
View(coord)

# este es un comando para hacer una seleccion automatica de K 
tess3_result <- tess_ktest(simple_dos, coord, Kvals = 1:10, ploidy = 2, K_selection = "auto")
summary(tess3_result)
# The tess3_result object contains results for the best-supported K value, including: 
# K: The value of the best-supported K (3, in this case)
# tess3_obj: Results from the cross-validation analysis of all values of K
# coords: Sampling coordinates
# Kvals: The range of K values that were tested
# grid: The RasterLayer upon which ancestry coefficients are mapped; NULL in this case
# pops: Population assignments (determined based on the maximum Q value) for each individual for the best K value

# Ahora que ya sabemos la K, la debemos exstraer para crear una matriz Q con los coeficientes de ancestria 
tess3_obj <- tess3_result$tess3_obj
bestK <- tess3_result[["K"]]
qmat <- qmatrix(tess3_obj, K = bestK) # Aqui extraemos la matriz Q
head(qmat)
tess_barplot(qmat)

# que paso si escogemos 2?
tess3_result <- tess_ktest(simple_dos, coord, Kvals = 1:10, ploidy = 2, K_selection = "manual",
                           tess_method = "qp")
summary(tess3_result)
tess3_obj <- tess3_result$tess3_obj
bestK <- tess3_result[["K"]]
qmat <- qmatrix(tess3_obj, K = bestK) # Aqui extraemos la matriz Q
head(qmat)
tess_barplot(qmat)


# que paso si escogemos 3?
tess3_result <- tess_ktest(simple_dos, coord, Kvals = 1:10, ploidy = 2,
                           K_selection = "manual")
summary(tess3_result)
tess3_obj <- tess3_result$tess3_obj
bestK <- tess3_result[["K"]]
qmat <- qmatrix(tess3_obj, K = bestK) # Aqui extraemos la matriz Q
head(qmat)
tess_barplot(qmat)


#                  #
#  DAPC           #
#               #

# Extraer los valores y vectores propios, esto es el paso inicial para estimar una matriz de distancia genetica 
eigenvalues <- pca_result$sdev^2
eigenvectors <- pca_result$rotation
# Utilizar el primer vector propio para calcular la matriz de distancias genéticas
# distance es de ecodist, funcion para calcular matricas de distancia o disimilaridad, actualmente 7 metricas se pueden calcular: "euclidean", "bray-curtis", 
# "manhattan", "mahalanobis" (squared Mahalanobis distance), "jaccard", "difference", "sorensen", "gower", 
# "modgower10" (modified Gower, base 10), "modgower2" (modified Gower, base 2).
distances <- distance(eigenvectors[, 1])
#distances2 <- distance(eigenvectors[, 1], method = "euclidean")
# Crear la matriz de distancias genéticas
genetic_distance_matrix <- as.matrix(distances)
# Ahora graficaremos la matriz de distancvias geneticas
heatmap(genetic_distance_matrix, main = "Mapa de Calor de Distancias Genéticas", Colv = NA, Rowv = NA, scale = "none") 
# me sale que es invalido el grafico 


#vamos a probar un admixture, cargamos algunos metadatos 
metadata_order<-read.csv("/home/omar/Documents/IND_PNDL/metadatos/meta_largos.csv")
ind_genlite$ind.names
metadata_order$ind
# Asignamos los individuos a grupos, pueen ser poblaciones, localidades, pero en este caso a los fenotipos sintomaticos y asintomaticos
pop(ind_genlite) <- metadata_order$tree_health
ind_genlite$pop
# cargamos la paqueteria adegenet para usar xvalDapc 
library(adegenet)
# Run a DAPC analysis by performing a cross validation test
pramx<-xvalDapc(tab(ind_genlite,NA.method="mean"), pop(ind_genlite))
pramx[-1] # vemos los resultados
# Create a DAPC plot
colores<-c("#440154","#74add1")
#"#4575b4","#ffd700","#9e0852","#ffeda0","#abd9e9","#00555e","#2e828b","#000000","#313695","#3288bd","#B6D000","#66c2a5","#95ee0dd6")
plotdapc <- scatter(pramx$DAPC, mstree = T, clabel = F, lwd = 2, grid=T, cex=3,
                    col = colores, cleg = 0.80, posi.da = "bottomleft" )

# Hacemos un dapc
DAPC1 <- dapc(ind_genlite,n.da=2,n.pca=50)
summary.dapc(DAPC1)
compoplot.dapc(DAPC1)
compoplot(pramx$DAPC)


# adiciaonalmente calculamos las distanias euclideanas para posteriormente comparar, ver tutorial Aligatr
euc_dists <- gen_dist(ind_PNDL, dist_type = "euclidean")
gen_dist_hm(euc_dists)
# tambien debemos estimar distancias con plink,  ver tutorial Aligatr
plink_dists <- gen_dist(plink_file = system.file("extdata", "liz_test.dist", package = "algatr"), 
                        plink_id_file = system.file("extdata", "liz_test.dist.id", package = "algatr"), dist_type = "plink")

# Ahora vamos a comprara los dos metodos
p_euc_plink <- gen_dist_corr(euc_dists, plink_dists, "Euclidean", "Plink")
p_pc_plink <- gen_dist_corr(pc_dists, plink_dists, "PC_based", "Plink")
plot_grid(p_euc_plink, p_pc_plink, nrow = 1)





#                                  #
#       kinship coefficient        #
#          Loiselle                #
#                                  #

calculateLoiselleKinship <- function(genotypes) {
  n_individuals <- nrow(genotypes)
  n_loci <- ncol(genotypes)
  kinship_matrix <- matrix(0, nrow = n_individuals, ncol = n_individuals)
  
  # Calcular las frecuencias alélicas por locus
  allele_frequencies <- colMeans(genotypes)
  
  # Calcular el coeficiente de parentesco entre cada par de individuos
  for (i in 1:(n_individuals - 1)) {
    for (j in (i + 1):n_individuals) {
      shared_allele_fraction <- (genotypes[i, ] * genotypes[j, ]) / (allele_frequencies ^ 2)
      kinship_coefficient <- mean(shared_allele_fraction) - 1
      kinship_matrix[i, j] <- kinship_matrix[j, i] <- kinship_coefficient
    }
  }
  
  return(kinship_matrix)
}

# Ejemplo de uso:
# genotypes <- matrix(c(1, 0, 1, 1, 1, 0, 0, 1, 1), nrow = 3, byrow = TRUE)
# kinship_matrix <- calculateLoiselleKinship(genotypes)
# print(kinship_matrix)

# en esta parte vamos a preprar los datos para ejecutar el script de python kinship_Loiselle.py y ps_FSGS.py
#creamos una matriz donde los individuos estan las filas y los alelos en las columnas 
write.csv(simple_dos, "~/Documents/IND_PNDL/estructura/coeficiente_correlacion/nxm_matriz.csv") 
#preparamos una matriz de las distanicias geograsficas y topograficas, se usara el pepiline de Aligatr
# distancias geograficas: 
mt_largos <- read.csv("~/Documents/IND_PNDL/metadatos/meta_largos.csv")
lat <- as.vector(mt_largos$X_coordinates_latitude)
lat
lon <- as.vector(mt_largos$X_coordinates_longitude) 
lon
individuos <- as.vector(mt_largos$ind_id)
individuos
mt_iinship <- read.csv("~/Documents/IND_PNDL/estructura/coeficiente_correlacion/kinship_matrix.csv")
kin_ind <- as.vector(mt_iinship$X)
kin_ind # solo para verficar que el orden de los individuos de las dos matriz sea igual

library(aligatr)
#install.packages("geodist")
library(geodist)
library(topoDistance)

# Suponiendo que tienes un data frame de coordenadas 'coord' con nombres en las filas
coord <- data.frame(
  longitude = lon, 
  latitude = lat,
  row.names = individuos
)

# Calculando la matriz de distancias
dist_matrix <- geodist(coord, measure = "haversine")
# Convertir a matriz y asegurar que los nombres se mantienen
dist_matrix <- as.matrix(dist_matrix)
rownames(dist_matrix) <- colnames(dist_matrix) <- rownames(coord)
View(dist_matrix)
plot(dist_matrix)
write.csv(dist_matrix, "~/Documents/IND_PNDL/estructura/coeficiente_correlacion/distancia_geodist.csv")
# Convertir a matriz y asegurar que los nombres se mantienen, pero usando el metodo de algatr
dist_matrix2 <- geo_dist(coord, type = "Euclidean") # metodo de algatr
dist_matrix2 <- as.matrix(dist_matrix2)
rownames(dist_matrix2) <- colnames(dist_matrix2) <- rownames(coord)
View(dist_matrix2)
plot(dist_matrix2)
write.csv(dist_matrix2, "~/Documents/IND_PNDL/estructura/coeficiente_correlacion/distancia_algatr.csv")

# en la terminal de linux corrimos el script ps_2_FSGS.py
sp <- read.csv("~/Documents/IND_PNDL/estructura/coeficiente_correlacion/FSGS_analysis_results_v2.csv")
x <- sp$Class
#c("2.98-14.84","14.84-62.06","62.06-249.98","249.98-997.96","997.96-3975.09")
x
y <- sp$Mean_Kinship
#c(3.1374501, 2.4831960, 2.6549195, 2.6143586, 2.6610841)
plot(y ~ x,)





################################################

# En la teminal necesitamos instalar spagedi, yo lo hice con las siguientes lineas 
# primero instale cmake: 
# $ sudo snap install cmake --classic
# despues descargue e instale spagedi:
# tar xvzf spagedi-*.tar.bz2
# cd spagedi-*/build
# cmake ..
# make
# make install


# spagedi necesita un archivo .txt donde esten especificados los genotipos, ver manual. nosotros usaremos el objeto simple_dos[1:5, 1:8] antes creado, 
# esto lo hacemos porque ya esta imputado, los individuos estan en las filas y porque es una tabla
simple_dos[1:5, 1:8]
#creamos un cvs para editarlo como nos dice el manual de spagedi
write.csv(simple_dos, "~/Documents/IND_PNDL/metadatos/geno_para_spagedi.csv")
#leemos el archivo editado
geno1 <- read.csv("/home/omar/Documents/IND_PNDL/metadatos/geno_para_spagedi.csv")
geno2 <- read.table("/home/omar/Documents/IND_PNDL/metadatos/snp_para_spagedi", sep = "\t")

# al parecer esto no funciona, en su lugar intente una conversion de mi archivo vcf a genepop con PGDSpider
# para instalar PGDSpider use el siguiente comando: # lo descarge de: 
# cd /usr/local/
# sudo cp ~/Downloads/PGDSpider_2.1.1.5.zip /usr/local/
# sudo unzip PGDSpider_2.1.1.5.zip
# sudo ln -s /usr/local/PGDSpider_2.1.1.5/PGDSpider2.sh /usr/local/bin/PGDSpider
# sudo chmod 755 /usr/local/PGDSpider_2.1.1.5/PGDSpider2.sh
# sudo gedit /usr/local/PGDSpider_2.1.1.5/PGDSpider2.sh
# Edit PGDSpider2.sh to read: #!/bin/bash
# java -Xmx4096m -Xms512m -jar /usr/local/PGDSpider_2.1.1.5/PGDSpider2.jar
# ./PGDSpider  <- previo a este paso cambie temporalmente a JAVA8 con el programa SDKMAN! 
#

# ahora para leer y para contruir un archivo de entrada para spagedi usare las siguiente paqueterias:
devtools::install_git("http://gitlab.mbb.univ-montp2.fr/jlopez/Genepop.git")
library(genepop) # usare GENEPOP para contruir un archivo de entrada para spagedi
devtools::install_github("kkeenan02/diveRsity")
library(diveRsity) 
devtools::install_github("rystanley/genepopedit") 
library(genepopedit) 

# Para usar spagedi en r debemos instalar el paquete rSpagedi
devtools::install_github("lukembrowne/rSpagedi")
library(rSpagedi)

runSpagedi(input_name = "/home/omar/Documents/IND_PNDL/datos_filtrados/ind_genepopo.txt",
           output_name = "/home/omar/Documents/IND_PNDL/datos_filtrados/output_spagedi.txt", 
           perm = T, n_perm = 99)

install.packages("graph4lg")
library(graph4lg)
ind_PNDL <- read.vcfR("~/Documents/IND_PNDL/datos_filtrados/omar_ind.recode.vcf")
ind_genind <- vcfR2genind(ind_PNDL)
ind_genind
ind_genpop <- suppressWarnings(genind_to_genepop(ind_genind, output = ind_genepop2))
write.table(ind_genpop, file = "ind_genepop2.txt")




install.packages("polysat")
library(polysat)
mygendata <- new("genambig", samples = c("ind1","ind2","ind3","ind4"),
                 loci = c("loc1", "loc2"))
mygendata <- reformatPloidies(mygendata, output="sample")
write.SPAGeDi("/home/omar/Documents/IND_PNDL/datos_filtrados/ind_genepopo.txt", spatcoord = "/home/omar/Documents/IND_PNDL/metadatos/coord", 
              file = "spagedifile.txt")




